{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "927c3350",
   "metadata": {},
   "source": [
    "# TRAINER 문서의 Trainer flags\n",
    "### 본 문서는 PyTorch Lightning의 [공식 가이드](https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html#trainer-flags)의 한글 번역본입니다. (옮긴이 [dnap512](https://github.com/dnap512), 21.7.15)\n",
    "\n",
    "#### 이번 문서는 너무 길어서 따로 분리했습니다. 원문에는 아래의 거의 모든 항목마다 동영상이 있으니 참고하시면 좋습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33720a0b",
   "metadata": {},
   "source": [
    "## accelerator\n",
    "\n",
    "사용할 accelerator backend(이전에는 distribution_backend로 알려짐).\n",
    "\n",
    "- (`'dp'`)는 DataParallel(동일한 시스템의 GPU 간 분할 배치)입니다.\n",
    "- (`'ddp'`)는 DistributedDataParallel입니다(각 노드의 각 GPU는 grads를 훈련하고 동기화함).\n",
    "- (`'ddp_cpu'`)는 CPU에서 DistributedDataParallel입니다('ddp'와 동일하지만 GPU를 사용하지 않습니다. 다중 노드 CPU 교육 또는 단일 노드 디버깅에 유용합니다. 단일 노드에서 속도 향상을 제공하지 **않습니다**. Torch는 이미 단일 시스템에서 여러 CPU를 효율적으로 사용하고 있습니다.)\n",
    "- (`'ddp2'`) 노드의 dp, 노드 전체의 ddp. negative sample의 수를 늘리는 것과 같은 작업에 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41d2176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(accelerator=None)\n",
    "\n",
    "# dp = DataParallel\n",
    "trainer = Trainer(gpus=2, accelerator='dp')\n",
    "\n",
    "# ddp = DistributedDataParallel\n",
    "trainer = Trainer(gpus=2, num_nodes=2, accelerator='ddp')\n",
    "\n",
    "# ddp2 = DistributedDataParallel + dp\n",
    "trainer = Trainer(gpus=2, num_nodes=2, accelerator='ddp2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f94a49f",
   "metadata": {},
   "source": [
    "> <span style='color:blue'>NOTE:</span> 이 옵션은 TPU에 적용되지 않습니다. TPU는 기본적으로 'ddp'를 사용합니다(각 코어에 대해).\n",
    "\n",
    "필요에 맞게 기존 가속기를 subclassing하여 하드웨어 동작을 수정할 수도 있습니다.\n",
    "\n",
    "다음 예를 확인하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f47ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOwnAcc(Accelerator):\n",
    "    ...\n",
    "\n",
    "Trainer(accelerator=MyOwnAcc())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecea05c",
   "metadata": {},
   "source": [
    "> <span style='color:red'>경고:</span> 사용자 지정 가속기를 전달하는 것은 실험적이며, 완전한 호환성을 위한 작업이 진행 중입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acdba89",
   "metadata": {},
   "source": [
    "## accumulate_grad_batches\n",
    "\n",
    "k 배치마다 또는 dict에 설정된 대로 grads를 누적합니다. 또한 Trainer는 설정한 배치의 마지막 번째 배치에서 `optimizer.step()`을 호출합니다. (역자 주: 메모리의 한계로 배치 사이즈를 줄여야 할 때, 이 옵션이 학습 상으로는 배치를 키울 수 있게 해줍니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bd0c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer (no accumulation)\n",
    "trainer = Trainer(accumulate_grad_batches=1)\n",
    "\n",
    "# accumulate every 4 batches (effective batch size is batch*4)\n",
    "trainer = Trainer(accumulate_grad_batches=4)\n",
    "\n",
    "# no accumulation for epochs 1-4. accumulate 3 for epochs 5-10. accumulate 20 after that\n",
    "trainer = Trainer(accumulate_grad_batches={5: 3, 10: 20})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d41a443",
   "metadata": {},
   "source": [
    "## amp_backend\n",
    "\n",
    "Use PyTorch AMP (‘native’) (available PyTorch 1.6+), or NVIDIA apex (‘apex’)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a968ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using PyTorch built-in AMP, default used by the Trainer\n",
    "trainer = Trainer(amp_backend='native')\n",
    "\n",
    "# using NVIDIA Apex\n",
    "trainer = Trainer(amp_backend='apex')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e52520",
   "metadata": {},
   "source": [
    "## amp_level\n",
    "\n",
    "The optimization level to use (O1, O2, etc…) for 16-bit GPU precision (using NVIDIA apex under the hood).\n",
    "\n",
    "Check [NVIDIA apex docs](https://nvidia.github.io/apex/amp.html#opt-levels) for level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09805a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(amp_level='O2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a015901",
   "metadata": {},
   "source": [
    "## auto_scale_batch_size\n",
    "\n",
    "훈련 전에 메모리에 맞는 가장 큰 배치 크기를 자동으로 찾으려고 시도합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3dbd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer (no scaling of batch size)\n",
    "trainer = Trainer(auto_scale_batch_size=None)\n",
    "\n",
    "# run batch size scaling, result overrides hparams.batch_size\n",
    "trainer = Trainer(auto_scale_batch_size='binsearch')\n",
    "\n",
    "# call tune to find the batch size\n",
    "trainer.tune(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af614df",
   "metadata": {},
   "source": [
    "## auto_select_gpus\n",
    "\n",
    "활성화되고 gpus가 정수인 경우 사용 가능한 GPU를 자동으로 선택합니다. 이는 GPU가 \"독점 모드\"로 구성되어 한 번에 하나의 프로세스만 GPU에 액세스할 수 있도록 구성된 경우에 특히 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d0d834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no auto selection (picks first 2 gpus on system, may fail if other process is occupying)\n",
    "trainer = Trainer(gpus=2, auto_select_gpus=False)\n",
    "\n",
    "# enable auto selection (will find two available gpus on system)\n",
    "trainer = Trainer(gpus=2, auto_select_gpus=True)\n",
    "\n",
    "# specifies all GPUs regardless of its availability\n",
    "Trainer(gpus=-1, auto_select_gpus=False)\n",
    "\n",
    "# specifies all available GPUs (if only one GPU is not occupied, uses one gpu)\n",
    "Trainer(gpus=-1, auto_select_gpus=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274f6d3d",
   "metadata": {},
   "source": [
    "## auto_lr_find\n",
    "\n",
    "`training.tune()`을 호출할 때, 최적의 초기 학습률을 찾기 위해 [Learning rate finder algorithm](https://arxiv.org/abs/1506.01186)을 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbbeb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer (no learning rate finder)\n",
    "trainer = Trainer(auto_lr_find=False)\n",
    "\n",
    "################\n",
    "\n",
    "# run learning rate finder, results override hparams.learning_rate\n",
    "trainer = Trainer(auto_lr_find=True)\n",
    "\n",
    "# call tune to find the lr\n",
    "trainer.tune(model)\n",
    "\n",
    "################\n",
    "\n",
    "# run learning rate finder, results override hparams.my_lr_arg\n",
    "trainer = Trainer(auto_lr_find='my_lr_arg')\n",
    "\n",
    "# call tune to find the lr\n",
    "trainer.tune(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd40939",
   "metadata": {},
   "source": [
    "> <span style='color:blue'>NOTE:</span> [Learning rate finder algorithm 가이드](https://pytorch-lightning.readthedocs.io/en/latest/advanced/lr_finder.html)를 살펴보세요. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea4a388",
   "metadata": {},
   "source": [
    "## benchmark\n",
    "\n",
    "true이면 `cudnn.benchmark`를 활성화합니다. 이 플래그는 입력 크기가 변경되지 않으면 시스템 속도를 높일 수 있습니다. 하지만 입력 크기가 변경되면 시스템이 느려질 수 있습니다.\n",
    "\n",
    "속도 향상은 cudnn auto-tunner가 하드웨어에 가장 적합한 알고리즘을 찾을 수 있도록 하는 데서 비롯됩니다[discussion 참조](https://discuss.pytorch.org/t/what-does-torch-backends-cudnn-benchmark-do/5936)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890a9afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(benchmark=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce18e337",
   "metadata": {},
   "source": [
    "## deterministic\n",
    "\n",
    "true이면 cudnn.deterministic을 활성화합니다. 시스템을 느리게 만들 수 있지만 재현성을 보장합니다. 또한 `$HOROVOD_FUSION_THRESHOLD=0`을 설정합니다.\n",
    "\n",
    "자세한 내용은 [pytorch docs](https://pytorch.org/docs/stable/notes/randomness.html)를 확인하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f0feac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(deterministic=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07040a9f",
   "metadata": {},
   "source": [
    "## callbacks\n",
    "\n",
    "[`Callback`](https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.callbacks.Callback.html#pytorch_lightning.callbacks.Callback) 목록을 추가합니다. Callback은 여기에 정의된 순서대로 순차적으로 실행됩니다(모든 상태가 체크포인트에 저장되도록 다른 모든 콜백 이후에 실행되는 [`ModelCheckpoint`] Callback 제외)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c44bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of callbacks\n",
    "callbacks = [PrintCallback()]\n",
    "trainer = Trainer(callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0585c8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "class PrintCallback(Callback):\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        print(\"Training is started!\")\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        print(\"Training is done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf4ca47",
   "metadata": {},
   "source": [
    "모델별 콜백은 [`configure_callbacks()`](https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.core.lightning.html#pytorch_lightning.core.lightning.LightningModule.configure_callbacks)를 통해 `LightningModule` 내부에 추가할 수도 있습니다. 이 Hook에서 반환된 콜백은 처음에 Trainer argument에 제공된 목록을 확장하고 동일한 유형의 두 개 이상이 있는 경우 트레이너 콜백을 대체합니다. [`ModelCheckpoint`](https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.callbacks.model_checkpoint.html#pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint) 콜백은 항상 마지막에 실행됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63af5305",
   "metadata": {},
   "source": [
    "## check_val_every_n_epoch\n",
    "\n",
    "매 에포크마다 Validation 수행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f9649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(check_val_every_n_epoch=1)\n",
    "\n",
    "# run val loop every 10 training epochs\n",
    "trainer = Trainer(check_val_every_n_epoch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc7e678",
   "metadata": {},
   "source": [
    "## checkpoint_callback\n",
    "\n",
    "기본적으로 Lightning은 현재 작업 디렉토리에 체크포인트(마지막 Training epoch의 state와 함께)를 저장하고 체크포인트는 모델에서 사용하는 모든 매개변수의 정확한 값을 캡처합니다. 자동 체크포인트를 비활성화하려면 False로 설정하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0115da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by Trainer\n",
    "trainer = Trainer(checkpoint_callback=True)\n",
    "\n",
    "# turn off automatic checkpointing\n",
    "trainer = Trainer(checkpoint_callback=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87db13da",
   "metadata": {},
   "source": [
    "[`ModelCheckpoint`](https://pytorch-lightning.readthedocs.io/en/latest/extensions/generated/pytorch_lightning.callbacks.ModelCheckpoint.html#pytorch_lightning.callbacks.ModelCheckpoint) 콜백을 초기화하고 [`callbacks`](https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.trainer.trainer.html#pytorch_lightning.trainer.trainer.Trainer.params.callbacks) 목록에 추가하여 기본 동작을 재정의할 수 있습니다. 체크포인트를 사용자 정의하는 방법은 [`Saving and Loading Weights docs`](https://pytorch-lightning.readthedocs.io/en/latest/common/weights_loading.html)를 참조하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf37b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "# Init ModelCheckpoint callback, monitoring 'val_loss'\n",
    "checkpoint_callback = ModelCheckpoint(monitor='val_loss')\n",
    "\n",
    "# Add your callback to the callbacks list\n",
    "trainer = Trainer(callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72210302",
   "metadata": {},
   "source": [
    "> <span style='color:red'>경고:</span> ModelCheckpoint 인스턴스를 이 인수에 전달하는 것은 v1.1부터 deprecated 되었으며 v1.3부터는 지원되지 않습니다. 대신 콜백 인수를 사용하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf3af7f",
   "metadata": {},
   "source": [
    "## default_root_dir\n",
    "\n",
    "로거 또는 [`pytorch_lightning.callbacks.ModelCheckpoint`] 콜백이 전달되지 않은 경우 로그 및 가중치가 저장되는 기본 경로입니다. 특정 클러스터에서는 로그와 체크포인트가 저장되는 위치를 분리해야 할 수 있습니다. 그렇지 않은 경우 편의를 위해 이 인수를 사용합니다. 경로는 로컬 경로 또는 s3://bucket/path 또는 'hdfs://path/'와 같은 원격 경로일 수 있습니다. 원격 파일 경로를 사용하려면 자격 증명을 설정해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787e032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(default_root_dir=os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ba51a0",
   "metadata": {},
   "source": [
    "## fast_dev_run\n",
    "\n",
    "모든 버그(즉, 일종의 단위 테스트)를 찾기 위한 목적으로, n으로 설정된 경우 n번의 배치 테스트를 수행하고, True로 설정된 경우 1번 배치 테스트를 수행합니다.\n",
    "\n",
    "내부에서 단일 배치로 fast_dev_run을 실행할 때 Psuedocode는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d88747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading\n",
    "__init__()\n",
    "prepare_data\n",
    "\n",
    "# test training step\n",
    "training_batch = next(train_dataloader)\n",
    "training_step(training_batch)\n",
    "\n",
    "# test val step\n",
    "val_batch = next(val_dataloader)\n",
    "out = validation_step(val_batch)\n",
    "validation_epoch_end([out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf62e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(fast_dev_run=False)\n",
    "\n",
    "# runs 1 train, val, test batch and program ends\n",
    "trainer = Trainer(fast_dev_run=True)\n",
    "\n",
    "# runs 7 train, val, test batches and program ends\n",
    "trainer = Trainer(fast_dev_run=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96db9800",
   "metadata": {},
   "source": [
    "> <span style='color:blue'>NOTE:</span> 이 인수는 `limit_train/val/test_batches`와 약간 다릅니다. 이 인수를 설정하면 tunner, checkpoint callbacks, early stopping callbacks, logger 및 `LearningRateLogger`와 같은 logger callback이 비활성화되고 1 epoch 동안만 실행됩니다. 이것은 디버깅 목적으로만 사용해야 합니다. `limit_train/val/test_batches`는 배치 수만 제한하고 아무 것도 비활성화하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe59767",
   "metadata": {},
   "source": [
    "## flush_logs_every_n_steps\n",
    "\n",
    "로깅 주기를 정합니다. [logging docs](https://pytorch-lightning.readthedocs.io/en/latest/extensions/logging.html)를 참고하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe3c516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(flush_logs_every_n_steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3abe4c6",
   "metadata": {},
   "source": [
    "## gpus\n",
    "\n",
    "- 학습에 사용할 gpu 수 (int)\n",
    "- 아니면 학습에 사용할 gpu의 번호 (list)\n",
    "- string값으로도 적용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb8d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer (ie: train on CPU)\n",
    "trainer = Trainer(gpus=None)\n",
    "\n",
    "# equivalent\n",
    "trainer = Trainer(gpus=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb981be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# int: train on 2 gpus\n",
    "trainer = Trainer(gpus=2)\n",
    "\n",
    "# list: train on GPUs 1, 4 (by bus ordering)\n",
    "trainer = Trainer(gpus=[1, 4])\n",
    "trainer = Trainer(gpus='1, 4') # equivalent\n",
    "\n",
    "# -1: train on all gpus\n",
    "trainer = Trainer(gpus=-1)\n",
    "trainer = Trainer(gpus='-1') # equivalent\n",
    "\n",
    "# combine with num_nodes to train on multiple GPUs across nodes\n",
    "# uses 8 gpus in total\n",
    "trainer = Trainer(gpus=2, num_nodes=4)\n",
    "\n",
    "# train only on GPUs 1 and 4 across nodes\n",
    "trainer = Trainer(gpus=[1, 4], num_nodes=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ece728e",
   "metadata": {},
   "source": [
    "## gradient_clip_val\n",
    "\n",
    "Gradient clipping 값을 정합니다. 0으로 적용하면 clipping하지 않는 것을 뜻합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc2c7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(gradient_clip_val=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaee2db",
   "metadata": {},
   "source": [
    "## limit_train_batches\n",
    "\n",
    "수행할 Training set의 양을 제한하여 적용합니다. Epoch가 끝날 때 발생하는 무언가를 디버깅하거나 테스트할 때 유용합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dc0b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(limit_train_batches=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aabe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(limit_train_batches=1.0)\n",
    "\n",
    "# run through only 25% of the training set each epoch\n",
    "trainer = Trainer(limit_train_batches=0.25)\n",
    "\n",
    "# run through only 10 batches of the training set each epoch\n",
    "trainer = Trainer(limit_train_batches=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49841a59",
   "metadata": {},
   "source": [
    "## limit_test_batches\n",
    "\n",
    "수행할 Test set의 양을 제한하여 적용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef38baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(limit_test_batches=1.0)\n",
    "\n",
    "# run through only 25% of the test set each epoch\n",
    "trainer = Trainer(limit_test_batches=0.25)\n",
    "\n",
    "# run for only 10 batches\n",
    "trainer = Trainer(limit_test_batches=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef68007",
   "metadata": {},
   "source": [
    "여러개의 Test dataloader의 경우 제한이 각 데이터 로더에 개별적으로 적용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b692f5",
   "metadata": {},
   "source": [
    "## limit_val_batches\n",
    "\n",
    "수행할 Valid set의 양을 제한하여 적용합니다. Epoch가 끝날 때 발생하는 무언가를 디버깅하거나 테스트할 때 유용합니다.\n",
    "\n",
    "여러개의 Valid dataloader의 경우 제한이 각 데이터 로더에 개별적으로 적용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab988f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(limit_val_batches=1.0)\n",
    "\n",
    "# run through only 25% of the validation set each epoch\n",
    "trainer = Trainer(limit_val_batches=0.25)\n",
    "\n",
    "# run for only 10 batches\n",
    "trainer = Trainer(limit_val_batches=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520d1cc9",
   "metadata": {},
   "source": [
    "## log_every_n_steps\n",
    "\n",
    "로깅 행을 실제 디스크에 얼마나 자주 추가할지 정합니다.(매 배치마다 실제 디스크에 로깅하게 되면 그만틈 느리겠죠)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7705409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(log_every_n_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572f920f",
   "metadata": {},
   "source": [
    "## log_gpu_memory\n",
    "\n",
    "옵션 목록\n",
    "\n",
    "- None\n",
    "- 'min_max'\n",
    "- 'all'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddabde99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(log_gpu_memory=None)\n",
    "\n",
    "# log all the GPUs (on master node only)\n",
    "trainer = Trainer(log_gpu_memory='all')\n",
    "\n",
    "# log only the min and max memory on the master node\n",
    "trainer = Trainer(log_gpu_memory='min_max')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9db6119",
   "metadata": {},
   "source": [
    "> <span style='color:blue'>NOTE:</span> `nvidia-smi`의 출력을 사용하기 때문에 성능이 느려질 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c28317",
   "metadata": {},
   "source": [
    "## logger\n",
    "\n",
    "실험 추적을 위한 [`Logger`](https://pytorch-lightning.readthedocs.io/en/latest/common/loggers.html)(or iterable collection of loggers). True 값은 아래의 기본 `TensorBoardLogger`를 사용합니다. False는 로깅을 비활성화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe91bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# default logger used by trainer\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir=os.getcwd(),\n",
    "    version=1,\n",
    "    name='lightning_logs'\n",
    ")\n",
    "Trainer(logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de616b57",
   "metadata": {},
   "source": [
    "## max_epochs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd25efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(max_epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1673b136",
   "metadata": {},
   "source": [
    "## min_epochs\n",
    "\n",
    "최소한 훈련할 epochs 수를 정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d347c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(min_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb13c887",
   "metadata": {},
   "source": [
    "## max_steps\n",
    "\n",
    "최대 Iteration 수를 정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc1a965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default (disabled)\n",
    "trainer = Trainer(min_steps=None)\n",
    "\n",
    "# Run at least for 100 steps (disable min_epochs)\n",
    "trainer = Trainer(min_steps=100, min_epochs=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384f4d92",
   "metadata": {},
   "source": [
    "## max_time\n",
    "\n",
    "훈련을 위한 최대 시간을 설정합니다. 지정 시간이 지나면 훈련은 중단됩니다. 사용자 지정 가능한 옵션의 경우 타이머 콜백을 사용하세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e676c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default (disabled)\n",
    "trainer = Trainer(max_time=None)\n",
    "\n",
    "# Stop after 12 hours of training or when reaching 10 epochs (string)\n",
    "trainer = Trainer(max_time=\"00:12:00:00\", max_epochs=10)\n",
    "\n",
    "# Stop after 1 day and 5 hours (dict)\n",
    "trainer = Trainer(max_time={\"days\": 1, \"hours\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844d47d8",
   "metadata": {},
   "source": [
    "`max_time`이 `min_steps` 또는 `min_epochs`와 함께 사용되는 경우 `min_*` 조건이 항상 더 높은 우선순위에 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173114f7",
   "metadata": {},
   "source": [
    "## num_nodes\n",
    "\n",
    "분산 학습을 목적으로 사용할 GPU 노드 수입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f47a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(num_nodes=1)\n",
    "\n",
    "# to train on 8 nodes\n",
    "trainer = Trainer(num_nodes=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dde8c9c",
   "metadata": {},
   "source": [
    "## num_processes\n",
    "\n",
    "학습할 프로세스의 수입니다. `accelerator=\"ddp\"`를 사용할 때 GPU 수로 자동 설정됩니다. `Accelerator=\"ddp_cpu\"`를 사용하여 GPU가 없는 머신에서 분산 교육을 모방할 때 1보다 큰 숫자로 설정합니다. 이것은 디버깅에 유용하지만 단일 프로세스 Torch가 이미 여러 CPU를 효율적으로 사용하고 있기 때문에 속도 향상을 제공하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd83f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate DDP for debugging on your GPU-less laptop\n",
    "trainer = Trainer(accelerator=\"ddp_cpu\", num_processes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ebf624",
   "metadata": {},
   "source": [
    "## num_sanity_val_steps\n",
    "\n",
    "Sanity check는 훈련을 시작하기 전에 n개의 val 배치를 수행합니다. 이렇게 하면 첫 번째  validation을 기다릴 필요 없이 유효성 검사의 모든 버그를 잡을 수 있습니다. Trainer는 기본적으로 2개 배치를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec110c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(num_sanity_val_steps=2)\n",
    "\n",
    "# turn it off\n",
    "trainer = Trainer(num_sanity_val_steps=0)\n",
    "\n",
    "# check all validation data\n",
    "trainer = Trainer(num_sanity_val_steps=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310ae0a0",
   "metadata": {},
   "source": [
    "이 옵션은 num_sanity_val_steps=0이 아닌 경우 val 데이터로더를 리셋합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c67b39b",
   "metadata": {},
   "source": [
    "## overfit_batches\n",
    "\n",
    "Training set에서 지정한 만큼의 데이터를 사용합니다. 0이 아니면 검증 및 테스트에 동일한 훈련 세트를 사용합니다. 훈련 데이터 로더가 shuffle=True이면 Lightning이 자동으로 비활성화합니다.\n",
    "\n",
    "빠르게 디버깅하거나 의도적으로 overfitting을 시도하는 데 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed6cf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(overfit_batches=0.0)\n",
    "\n",
    "# use only 1% of the train set (and use the train set for val and test)\n",
    "trainer = Trainer(overfit_batches=0.01)\n",
    "\n",
    "# overfit on 10 of the same batches\n",
    "trainer = Trainer(overfit_batches=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd885bb1",
   "metadata": {},
   "source": [
    "## plugins\n",
    "\n",
    "[plugins](https://pytorch-lightning.readthedocs.io/en/latest/extensions/plugins.html#plugins)는 여러분이 임의의  backends, precision libraries, clusters 등에 연결하게 해줍니다.\n",
    "\n",
    "- [DDP](https://pytorch-lightning.readthedocs.io/en/latest/advanced/multi_gpu.html#multi-gpu)\n",
    "- [TorchElastic](https://pytorch.org/elastic/0.2.2/index.html)\n",
    "- [Apex](https://pytorch-lightning.readthedocs.io/en/latest/guides/speed.html#amp)\n",
    "\n",
    "여러분만의 behavior를 정의하려면 관련 클래스를 하위 클래스로 만들고 전달하세요. 다음은 여러분만의 [`ClusterEnvironment`](https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.plugins.environments.ClusterEnvironment.html#pytorch_lightning.plugins.environments.ClusterEnvironment)를 연결하는 예입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaf47c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.plugins.environments import ClusterEnvironment\n",
    "\n",
    "class MyCluster(ClusterEnvironment):\n",
    "\n",
    "    def master_address(self):\n",
    "        return your_master_address\n",
    "\n",
    "    def master_port(self):\n",
    "        return your_master_port\n",
    "\n",
    "    def world_size(self):\n",
    "        return the_world_size\n",
    "\n",
    "trainer = Trainer(plugins=[MyCluster()], ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdde6923",
   "metadata": {},
   "source": [
    "## prepare_data_per_node\n",
    "\n",
    "True이면 모든 노드에 대해 `LOCAL_RANK=0`에서 `prepare_data()`를 호출합니다. False라면 `NODE_RANK=0`, `LOCAL_RANK=0`에서만 호출됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c693120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default\n",
    "Trainer(prepare_data_per_node=True)\n",
    "\n",
    "# use only NODE_RANK=0, LOCAL_RANK=0\n",
    "Trainer(prepare_data_per_node=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3823ad",
   "metadata": {},
   "source": [
    "## precision\n",
    "\n",
    "Lightning은 double precision(64), full precision(32) 또는 half precision(16) 훈련을 지원합니다.\n",
    "\n",
    "Half precision 또는 mixed precision은 32비트 및 16비트 부동 소수점을 결합하여 모델 훈련 중에 메모리 공간을 줄이는 것입니다. 그 결과 성능이 향상되어 최신 GPU에서 +3배의 속도 향상을 달성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df28186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(precision=32, gpus=1)\n",
    "\n",
    "# 16-bit precision\n",
    "trainer = Trainer(precision=16, gpus=1)\n",
    "\n",
    "# 64-bit precision\n",
    "trainer = Trainer(precision=64, gpus=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8d2d5e",
   "metadata": {},
   "source": [
    "> <span style='color:blue'>NOTE:</span> TPU 상에서 돌아갈 때, torch.float16이 사용되지만 텐서 인쇄에는 여전히 torch.float32가 표시됩니다.\n",
    "\n",
    "> <span style='color:blue'>NOTE:</span> 16bit precision은 CPU 상에서 지원되지 않습니다.\n",
    "\n",
    "> <span style='color:red'>PYTORCH 1.6+를 사용할 때 LIGHTNING은 네이티브 AMP 구현을 사용하여 16bit precision을 지원합니다. 1.6 버전 이하의 PYTORCH 16bit precision은 NVIDIA APEX 라이브러리에서 지원됩니다.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57bddf6",
   "metadata": {},
   "source": [
    "## process_position\n",
    "\n",
    "Progress bar를 주문합니다. 동일한 노드에서 여러 트레이너를 실행할 때 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad0279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(process_position=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfe965f",
   "metadata": {},
   "source": [
    "> <span style='color:blue'>NOTE:</span> 사용자 정의 콜백이 `callbacks`에 전달되면 이 인수는 무시됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c21866",
   "metadata": {},
   "source": [
    "## profiler\n",
    "\n",
    "모델 훈련 중 각각의 단계를 프로파일링하고 병목 현상을 찾아내는 데 도움이 됩니다.\n",
    "\n",
    "자세한 사항은 [profiler docs](https://pytorch-lightning.readthedocs.io/en/latest/advanced/profiler.html)를 참고하세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e3337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.profiler import SimpleProfiler, AdvancedProfiler\n",
    "\n",
    "# default used by the Trainer\n",
    "trainer = Trainer(profiler=None)\n",
    "\n",
    "# to profile standard training events, equivalent to `profiler=SimpleProfiler()`\n",
    "trainer = Trainer(profiler=\"simple\")\n",
    "\n",
    "# advanced profiler for function-level stats, equivalent to `profiler=AdvancedProfiler()`\n",
    "trainer = Trainer(profiler=\"advanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b4c05b",
   "metadata": {},
   "source": [
    "## progress_bar_refresh_rate\n",
    "\n",
    "Progress bar를 얼마나 자주 새로고침 할지 정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320d1f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(progress_bar_refresh_rate=1)\n",
    "\n",
    "# disable progress bar\n",
    "trainer = Trainer(progress_bar_refresh_rate=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2838b2c9",
   "metadata": {},
   "source": [
    "Note:\n",
    "- Google Colab 노트북에서는 화면 새로 고침 빈도로 인해 더 빠른 새로 고침 빈도(낮은 숫자)가 충돌하는 것으로 알려져 있습니다. 사용자가 값을 제공하지 않으면 Lightning은 이러한 환경에서 이 값을 20으로 설정합니다.\n",
    "\n",
    "- 사용자 정의 콜백이 `callbacks`에 전달되면 이 인수는 무시됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29301cb1",
   "metadata": {},
   "source": [
    "## reload_dataloaders_every_n_epochs\n",
    "\n",
    "양의 정수(n)로 설정하면 n epoch마다 데이터로더를 다시 로드합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f545e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 0 (default)\n",
    "train_loader = model.train_dataloader()\n",
    "for epoch in epochs:\n",
    "    for batch in train_loader:\n",
    "        ...\n",
    "\n",
    "# if a positive integer\n",
    "for epoch in epochs:\n",
    "    if not epoch % reload_dataloaders_every_n_epochs:\n",
    "        train_loader = model.train_dataloader()\n",
    "    for batch in train_loader:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc157ae2",
   "metadata": {},
   "source": [
    "## replace_sampler_ddp\n",
    "\n",
    "[`DistributedSampler`](https://pytorch.org/docs/stable/data.html#torch.utils.data.distributed.DistributedSampler)의 자동 추가를 활성화합니다. PyTorch에서는 TPU 또는 다중 노드와 같은 분산 설정에서 사용해야 합니다. 샘플러는 각 GPU가 데이터의 적절한 부분을 볼 수 있도록 합니다. 기본적으로 train 샘플러에는 `shuffle=True`가 추가되고 val/test 샘플러에는 shuffle=False가 추가됩니다. 이를 사용자 정의하려면 `replace_sampler_ddp=False`를 설정하고 여러분만의 분산 샘플러를 추가할 수 있습니다. `replace_sampler_ddp=True`이고 분산 샘플러가 이미 추가된 경우 Lightning이 기존 샘플러를 대체하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673af4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(replace_sampler_ddp=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578636e7",
   "metadata": {},
   "source": [
    "False로 설정하면 여러분만의 분산 샘플러를 추가해야 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in your LightningModule or LightningDataModule\n",
    "def train_dataloader(self):\n",
    "    # default used by the Trainer\n",
    "    sampler = torch.utils.data.distributed.DistributedSampler(dataset, shuffle=True)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, sampler=sampler)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cf571f",
   "metadata": {},
   "source": [
    "> <span style='color:blue'>NOTE:</span> Iterable dataset에 대해서 자동으로 적용하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59128c7d",
   "metadata": {},
   "source": [
    "## resume_from_checkpoint\n",
    "\n",
    "특정 체크포인트에서 훈련을 재개하려면 여기에 경로를 입력하세요. Epoch 중간의 체크포인트에서 다시 시작하면 다음 에포크 시작 부분부터 훈련이 시작됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1778fd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(resume_from_checkpoint=None)\n",
    "\n",
    "# resume from a specific checkpoint\n",
    "trainer = Trainer(resume_from_checkpoint='some/path/to/my_checkpoint.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f92722",
   "metadata": {},
   "source": [
    "## sync_batchnorm\n",
    "\n",
    "모든 GPU에서 batchnorm 층간의 동기화를 활성화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a03784",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(sync_batchnorm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e77b170",
   "metadata": {},
   "source": [
    "## track_grad_norm\n",
    "\n",
    "- 추적하지 않음 (-1)\n",
    "- 특정 norm에 대해 추적함 (2면 2-norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c193ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(track_grad_norm=-1)\n",
    "\n",
    "# track the 2-norm\n",
    "trainer = Trainer(track_grad_norm=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c64e90",
   "metadata": {},
   "source": [
    "## tpu_cores\n",
    "\n",
    "- 학습할 TPU 코어 수(1 또는 8).\n",
    "- 학습할 TPU 코어 \\[1-8\\]\n",
    "\n",
    "단일 TPU v2 또는 v3에는 8개의 코어가 있습니다. TPU 포드에는 최대 2048개의 코어가 있습니다. POD 슬라이스는 요청한 만큼의 코어를 얻을 수 있음을 의미합니다.\n",
    "\n",
    "효과적인 배치 크기는 batch_size * 총 tpu 코어입니다.\n",
    "\n",
    "이 매개변수는 1 또는 8일 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6471ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your_trainer_file.py\n",
    "\n",
    "# default used by the Trainer (ie: train on CPU)\n",
    "trainer = Trainer(tpu_cores=None)\n",
    "\n",
    "# int: train on a single core\n",
    "trainer = Trainer(tpu_cores=1)\n",
    "\n",
    "# list: train on a single selected core\n",
    "trainer = Trainer(tpu_cores=[2])\n",
    "\n",
    "# int: train on all cores few cores\n",
    "trainer = Trainer(tpu_cores=8)\n",
    "\n",
    "# for 8+ cores must submit via xla script with\n",
    "# a max of 8 cores specified. The XLA script\n",
    "# will duplicate script onto each TPU in the POD\n",
    "trainer = Trainer(tpu_cores=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9028f9",
   "metadata": {},
   "source": [
    "8개 이상의 코어(즉, POD)에서 훈련하려면 xla_dist 스크립트를 사용하여 이 스크립트를 제출하십시오.\n",
    "\n",
    "```bash\n",
    "python -m torch_xla.distributed.xla_dist\n",
    "--tpu=$TPU_POD_NAME\n",
    "--conda-env=torch-xla-nightly\n",
    "--env=XLA_USE_BF16=1\n",
    "-- python your_trainer_file.py\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64714850",
   "metadata": {},
   "source": [
    "## truncated_bptt_steps\n",
    "\n",
    "truncated_bptt_steps는 훨씬 긴 시퀀스의 k 단계마다 역전파를 수행합니다.\n",
    "\n",
    "이것이 활성화되면 배치가 자동으로 잘리고 trainer가 잘린 Backprop을 적용합니다.\n",
    "\n",
    "[(Williams et al. “An efficient gradient-based algorithm for on-line training of recurrent network trajectories.”)](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.7941&rep=rep1&type=pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d743c29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer (ie: disabled)\n",
    "trainer = Trainer(truncated_bptt_steps=None)\n",
    "\n",
    "# backprop every 5 steps in a batch\n",
    "trainer = Trainer(truncated_bptt_steps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b098668d",
   "metadata": {},
   "source": [
    "> <span style='color:blue'>NOTE:</span> 배치에 시퀀스 차원이 있는지 확인하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189b38f3",
   "metadata": {},
   "source": [
    "Lightning은 time dimension에 따라 배치를 분할합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc582e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the second as the time dimension\n",
    "# (batch, time, ...)\n",
    "sub_batch = batch[0, 0:t, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0036ba29",
   "metadata": {},
   "source": [
    "이 기능을 사용하려면 hidden state가 assign된 `hiddens` parameter를 포함하도록 LightningModule의 `pytorch_lightning.core.LightningModule.training_step()`을 업데이트해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f131447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncated back-propagation through time\n",
    "def training_step(self, batch, batch_idx, hiddens):\n",
    "    # hiddens are the hiddens from the previous truncated backprop step\n",
    "    out, hiddens = self.lstm(data, hiddens)\n",
    "    return {\n",
    "        \"loss\": ...,\n",
    "        \"hiddens\": hiddens\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d594a4",
   "metadata": {},
   "source": [
    "## val_check_interval\n",
    "\n",
    "한 개의 training epoch 내에서 valid를 수행하는 빈도입니다. float 또는 int로 지정할 수 있습니다.\n",
    "\n",
    "- (float): Training epoch 내에서 자주 valid 하는 정도\n",
    "- (int): n steps 마다 valid 수행\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abf77da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(val_check_interval=1.0)\n",
    "\n",
    "# check validation set 4 times during a training epoch\n",
    "trainer = Trainer(val_check_interval=0.25)\n",
    "\n",
    "# check validation set every 1000 training batches\n",
    "# use this when using iterableDataset and your dataset has no length\n",
    "# (ie: production cases with streaming data)\n",
    "trainer = Trainer(val_check_interval=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b89e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the computation to estimate the total number of batches seen within an epoch.\n",
    "\n",
    "# Find the total number of train batches\n",
    "total_train_batches = total_train_samples // (train_batch_size * world_size)\n",
    "\n",
    "# Compute how many times we will call validation during the training loop\n",
    "val_check_batch = max(1, int(total_train_batches * val_check_interval))\n",
    "val_checks_per_epoch = total_train_batches / val_check_batch\n",
    "\n",
    "# Find the total number of validation batches\n",
    "total_val_batches = total_val_samples // (val_batch_size * world_size)\n",
    "\n",
    "# Total number of batches run\n",
    "total_fit_batches = total_train_batches + total_val_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b084a9",
   "metadata": {},
   "source": [
    "## weights_save_path\n",
    "\n",
    "만약 지정하고 싶다면 가중치를 어디에 저장할지 지정하세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4342433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer\n",
    "trainer = Trainer(weights_save_path=os.getcwd())\n",
    "\n",
    "# save to your custom path\n",
    "trainer = Trainer(weights_save_path='my/path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb60ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if checkpoint callback used, then overrides the weights path\n",
    "# **NOTE: this saves weights to some/path NOT my/path\n",
    "checkpoint = ModelCheckpoint(dirpath='some/path')\n",
    "trainer = Trainer(\n",
    "    callbacks=[checkpoint],\n",
    "    weights_save_path='my/path'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e4db06",
   "metadata": {},
   "source": [
    "## weights_summary\n",
    "\n",
    "훈련이 시작될 때 가중치에 대한 요약을 출력합니다. (옵션: 'full', 'top', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c384f32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default used by the Trainer (ie: print summary of top level modules)\n",
    "trainer = Trainer(weights_summary='top')\n",
    "\n",
    "# print full summary of all modules and submodules\n",
    "trainer = Trainer(weights_summary='full')\n",
    "\n",
    "# don't print a summary\n",
    "trainer = Trainer(weights_summary=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
