{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca6f3599",
   "metadata": {},
   "source": [
    "# LIGHTNING IN 2 STEPS\n",
    "### 본 문서는 PyTorch Lightning의 [공식 가이드](https://pytorch-lightning.readthedocs.io/en/latest/starter/new-project.html#lightning-in-2-steps)의 한글 번역본입니다. (옮긴이 [dnap512](https://github.com/dnap512), 21.7.13)\n",
    "**이번 가이드에서는 PyTorch 코드를 Lightning으로 어떻게 구성할 수 있는지 2 단계로 설명합니다.**\n",
    "\n",
    "PyTorch Lightning으로 코드를 구성하면 코드를 다음과 같이 만들 수 있습니다.\n",
    "\n",
    "- PyTorch의 유연성을 유지하면서도, 반복적으로 비슷한 형태를 띄는 코드 무더기(a ton of boilerplate code)를 없앨 수 있습니다.\n",
    "- 엔지니어링에서 연구를 위한 코드를 분리하여 가독성을 높일 수 있습니다.\n",
    "- 재현이 더 쉬워집니다.\n",
    "- Training loop와 까다로운 엔지니어링 코드 대부분을 자동화하여 오류를 감소시킵니다.\n",
    "- 모델 변경없이 어떠한 하드웨어 조건에서도 Scalable 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564ceff5",
   "metadata": {},
   "source": [
    "## Step 0: PyTorch Lightning 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3088d08b",
   "metadata": {},
   "source": [
    "pip를 이용하여 설치하거나,\n",
    "```bash\n",
    "pip install pytorch-lightning\n",
    "```\n",
    "\n",
    "conda를 이용하여 설치할 수 있습니다.\n",
    "```bash\n",
    "conda install pytorch-lightning -c conda-forge\n",
    "```\n",
    "\n",
    "혹은 conda 환경에서도 설치할 수 있습니다.\n",
    "```bash\n",
    "conda activate my_env\n",
    "pip install pytorch-lightning\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618cda4f",
   "metadata": {},
   "source": [
    "## Step 1: LightningModule 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabc5493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e2d450",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitAutoEncoder(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 3)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 28*28)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # lightning에서는, forward 함수는 prediction/inference action을 정의합니다.\n",
    "        embedding = self.encoder(x)\n",
    "        return embedding\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step은 train loop를 정의합니다.\n",
    "        # forward 함수와는 독립적입니다.\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        # 기본적으로 Tensorboard에 logging합니다.\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e79f8f7",
   "metadata": {},
   "source": [
    "### System과 Model\n",
    "\n",
    "[LightningModule](https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html)은 모델이 아니라 시스템을 정의합니다. (아래 그림을 참고하세요)\n",
    "![module](https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/pl_docs/model_system.png)\n",
    "\n",
    "\n",
    "시스템의 예:\n",
    "- [Autoencoder](https://github.com/PyTorchLightning/lightning-bolts/blob/master/pl_bolts/models/autoencoders/basic_ae/basic_ae_module.py)\n",
    "- [BERT](https://colab.research.google.com/github/PytorchLightning/pytorch-lightning/blob/master/notebooks/04-transformers-text-classification.ipynb)\n",
    "- [DQN](https://colab.research.google.com/github/PytorchLightning/pytorch-lightning/blob/master/notebooks/08-Domain-specific-demos.ipynb)\n",
    "- [GAN](https://colab.research.google.com/github/PytorchLightning/pytorch-lightning/blob/master/notebooks/03-basic-gan.ipynb)\n",
    "- [Image classifier](https://colab.research.google.com/github/PytorchLightning/pytorch-lightning/blob/master/notebooks/01-mnist-hello-world.ipynb)\n",
    "- Seq2seq\n",
    "- [SimCLR](https://github.com/PyTorchLightning/lightning-bolts/blob/master/pl_bolts/models/self_supervised/simclr/simclr_module.py)\n",
    "- [VAE](https://github.com/PyTorchLightning/lightning-bolts/blob/master/pl_bolts/models/autoencoders/basic_vae/basic_vae_module.py)\n",
    "\n",
    "내부에서 LightningModule은 여전히 모든 연구 코드를 단일 파일로 그룹화하여 독립적으로 만드는 torch.nn.Module에 불과합니다:\n",
    "\n",
    "- The Train loop\n",
    "- The Validation loop\n",
    "- The Test loop\n",
    "- The Model or system of Models\n",
    "- The Optimizer\n",
    "\n",
    "여러분은 사용 가능한 Callback hooks에서 찾을 수 있는 20개 이상의 hooks를 재정의하여 Training의 모든 부분(예: Backward pass)을 Customizing할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dbe708",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitAutoEncoder(LightningModule):\n",
    "\n",
    "    def backward(self, loss, optimizer, optimizer_idx):\n",
    "        loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bde313",
   "metadata": {},
   "source": [
    "### FORWARD와 TRAINING_STEP\n",
    "\n",
    "Lightning에서는 Training과 Inference를 분리합니다. Training_step은 전체 훈련 루프를 정의합니다. 우리는 사용자가 Inference 작업을 정의하기 위해 `forward`를 사용할 것을 권장합니다.\n",
    "\n",
    "예를 들어, 이 경우 임베딩 추출기로 작동하도록 오토인코더를 정의할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6d2952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "    embeddings = self.encoder(x)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52a7d66",
   "metadata": {},
   "source": [
    "당연하게도, `training_step` 내에서도 `forward` 함수를 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ff6a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    ...\n",
    "    z = self(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f43c0b6",
   "metadata": {},
   "source": [
    "이러한 것들은 정말로 여러분의 구현에 따라 달라집니다. 그러나 다음 사항들은 유지하는 것이 좋습니다.\n",
    "\n",
    "- Inference (predicting)를 목적으로 `forward` 사용\n",
    "- Training을 목적으로 `training_step` 사용\n",
    "\n",
    "자세한 것들은 [lightning module](https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html) docs를 참고하세요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d48080",
   "metadata": {},
   "source": [
    "## Step 2: Fit with Lightning Trainer\n",
    "\n",
    "먼저 원하는 대로 데이터를 정의합니다. Lightning은 train/val/test 분할을 위한 [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)만 있으면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15317680",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557a73b6",
   "metadata": {},
   "source": [
    "다음으로, [Lightning module](https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html)과 PyTorch Lightning `Trainer`를 초기화한 다음 데이터와 모델 모두에 적합하게 호출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12403fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "autoencoder = LitAutoEncoder()\n",
    "\n",
    "# most basic trainer, uses good defaults (auto-tensorboard, checkpoints, logs, and more)\n",
    "# trainer = pl.Trainer(gpus=8) (if you have GPUs)\n",
    "trainer = pl.Trainer()\n",
    "trainer.fit(autoencoder, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552b8173",
   "metadata": {},
   "source": [
    "```Trainer```는 다음 사항을 자동화합니다.\n",
    "\n",
    "- Epoch and batch iteration\n",
    "- Calling of optimizer.step(), backward, zero_grad()\n",
    "- Calling of .eval(), enabling/disabling grads\n",
    "- weights loading\n",
    "- Tensorboard (see loggers options)\n",
    "- Multi-GPU support\n",
    "- TPU\n",
    "- 16-bit precision AMP support\n",
    "\n",
    "\n",
    ">Tip: \n",
    "여러분이 만약 수동적으로 Optimizer들을 관리하는것을 선호한다면, 여러분은 the Manual optimization mode를 사용할 수 있습니다 (ie: RL, GANs, etc…).\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**이게 전부입니다!**\n",
    "\n",
    "다음은 Lightning에서 알아야 할 주요 2가지 개념입니다. Lightning의 다른 모든 기능은 Trainer 또는 LightningModule의 기능입니다.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4021ae43",
   "metadata": {},
   "source": [
    "## 기본적인 특징들\n",
    "### Manual vs Automaitic optimization\n",
    "\n",
    "#### Automatic optimization\n",
    "\n",
    "Lightning을 사용하면, Training_step에서 Attached graph로 손실을 반환하는 한 grad를 활성화/비활성화하거나, Backward pass를 수행하거나, Optimizer를 업데이트할 때 걱정할 필요가 없습니다. Lightning이 최적화를 자동화합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65d4591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    loss = self.encoder(batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358eb4b7",
   "metadata": {},
   "source": [
    "#### Manual optimization\n",
    "\n",
    "하지만 특히 GAN같은 연구나 강화학습, 또는 여러개의 Optimizer를 사용하는 등의 경우에서는 여러분들이 Automatic optimization을 끄고 Training loop를 완전히 통제할 수 있습니다.\n",
    "\n",
    "Automatic optimization을 끄고, 여러분이 Train loop를 통제해보세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484fd049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self):\n",
    "    self.automatic_optimization = False\n",
    "\n",
    "def training_step(self, batch, batch_idx):\n",
    "    # access your optimizers with use_pl_optimizer=False. Default is True\n",
    "    opt_a, opt_b = self.optimizers(use_pl_optimizer=True)\n",
    "\n",
    "    loss_a = self.generator(batch)\n",
    "    opt_a.zero_grad()\n",
    "    # use `manual_backward()` instead of `loss.backward` to automate half precision, etc...\n",
    "    self.manual_backward(loss_a)\n",
    "    opt_a.step()\n",
    "\n",
    "    loss_b = self.discriminator(batch)\n",
    "    opt_b.zero_grad()\n",
    "    self.manual_backward(loss_b)\n",
    "    opt_b.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890af173",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a87753",
   "metadata": {},
   "source": [
    "### Predict or Deploy\n",
    "\n",
    "여러분이 훈련을 수행할 때, Prediction을 위한 LightningModule의 3가지 옵션이 있습니다.\n",
    "\n",
    "#### Option 1: Sub-models\n",
    "\n",
    "예측을 위해 시스템 내부의 모든 모델을 꺼냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777d1de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "# to use as embedding extractor\n",
    "# ----------------------------------\n",
    "autoencoder = LitAutoEncoder.load_from_checkpoint('path/to/checkpoint_file.ckpt')\n",
    "encoder_model = autoencoder.encoder\n",
    "encoder_model.eval()\n",
    "\n",
    "# ----------------------------------\n",
    "# to use as image generator\n",
    "# ----------------------------------\n",
    "decoder_model = autoencoder.decoder\n",
    "decoder_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f675ad15",
   "metadata": {},
   "source": [
    "#### Option 2: Forward\n",
    "\n",
    "원하는 대로 예측을 수행하기 위해 forward 메서드를 추가할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4444d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "# using the AE to extract embeddings\n",
    "# ----------------------------------\n",
    "class LitAutoEncoder(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential()\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedding = self.encoder(x)\n",
    "        return embedding\n",
    "\n",
    "autoencoder = LitAutoEncoder()\n",
    "autoencoder = autoencoder(torch.rand(1, 28 * 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16807275",
   "metadata": {},
   "source": [
    "#### Option 3: Production\n",
    "\n",
    "Production system의 경우 onnx 또는 torchscript가 훨씬 빠릅니다. forward method를 추가했는지 확인하거나 필요한 sub-model만 추적하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aff56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "# torchscript\n",
    "# ----------------------------------\n",
    "autoencoder = LitAutoEncoder()\n",
    "torch.jit.save(autoencoder.to_torchscript(), \"model.pt\")\n",
    "os.path.isfile(\"model.pt\")\n",
    "\n",
    "# ----------------------------------\n",
    "# onnx\n",
    "# ----------------------------------\n",
    "with tempfile.NamedTemporaryFile(suffix='.onnx', delete=False) as tmpfile:\n",
    "     autoencoder = LitAutoEncoder()\n",
    "     input_sample = torch.randn((1, 28 * 28))\n",
    "     autoencoder.to_onnx(tmpfile.name, input_sample, export_params=True)\n",
    "     os.path.isfile(tmpfile.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e36900",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecc6c6f",
   "metadata": {},
   "source": [
    "### Using CPUs/GPUs/TPUs\n",
    "\n",
    "Lightning에서 CPU, GPU 또는 TPU를 사용하는 것은 간단합니다. 코드를 변경할 필요가 없습니다. 트레이너 옵션만 변경하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee1bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on CPU\n",
    "trainer = Trainer()\n",
    "\n",
    "# train on 8 CPUs\n",
    "trainer = Trainer(num_processes=8)\n",
    "\n",
    "# train on 1024 CPUs across 128 machines\n",
    "trainer = pl.Trainer(\n",
    "    num_processes=8,\n",
    "    num_nodes=128\n",
    ")\n",
    "\n",
    "# train on 1 GPU\n",
    "trainer = pl.Trainer(gpus=1)\n",
    "\n",
    "# train on multiple GPUs across nodes (32 gpus here)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=4,\n",
    "    num_nodes=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58808e51",
   "metadata": {},
   "source": [
    "코드의 한 줄을 변경하지 않고 이제 아래 코드로 구현할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732905d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on TPUs using 16 bit precision\n",
    "# using only half the training data and checking validation every quarter of a training epoch\n",
    "trainer = pl.Trainer(\n",
    "    tpu_cores=8,\n",
    "    precision=16,\n",
    "    limit_train_batches=0.5,\n",
    "    val_check_interval=0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f09520",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7372c666",
   "metadata": {},
   "source": [
    "### Checkpoints\n",
    "\n",
    "Lightning은 모델을 자동으로 저장합니다. 훈련을 마치면 다음과 같이 체크포인트를 로드할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c542145",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitModel.load_from_checkpoint(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02bc66b",
   "metadata": {},
   "source": [
    "위의 체크포인트에는 모델을 초기화하고 상태 dict를 설정하는 데 필요한 모든 인수가 포함되어 있습니다. 수동으로 수행하려는 경우 아래 방법이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a827ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ckpt\n",
    "ckpt = torch.load('path/to/checkpoint.ckpt')\n",
    "\n",
    "# equivalent to the above\n",
    "model = LitModel()\n",
    "model.load_state_dict(ckpt['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46eff22",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5652eca3",
   "metadata": {},
   "source": [
    "### Data flow\n",
    "\n",
    "각 loop (training, validation, test) 여러분이 구현할 수 있는 3개의 hook이 있습니다.\n",
    "- x_step\n",
    "- x_step_end\n",
    "- x_epoch_end\n",
    "\n",
    "다음의 예에서는 데이터 흐름을 설명하기 위해 훈련 루프(예: x=training)를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e51b9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = []\n",
    "for batch in data:\n",
    "    out = training_step(batch)\n",
    "    outs.append(out)\n",
    "training_epoch_end(outs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcad3b15",
   "metadata": {},
   "source": [
    "The equivalent in Lightning is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536ec1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    prediction = ...\n",
    "    return prediction\n",
    "\n",
    "def training_epoch_end(self, training_step_outputs):\n",
    "    for prediction in predictions:\n",
    "        # do something with these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecc1131",
   "metadata": {},
   "source": [
    "DP 또는 DDP2 분산 모드를 사용하는 경우(예: GPU 간에 배치 분할) x_step_end를 사용하여 수동으로 집계합니다(또는 Lightning이 자동 집계하도록 구현하지 마십시오)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76408f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in data:\n",
    "    model_copies = copy_model_per_gpu(model, num_gpus)\n",
    "    batch_split = split_batch_per_gpu(batch, num_gpus)\n",
    "\n",
    "    gpu_outs = []\n",
    "    for model, batch_part in zip(model_copies, batch_split):\n",
    "        # LightningModule hook\n",
    "        gpu_out = model.training_step(batch_part)\n",
    "        gpu_outs.append(gpu_out)\n",
    "\n",
    "    # LightningModule hook\n",
    "    out = training_step_end(gpu_outs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f2851c",
   "metadata": {},
   "source": [
    "Lightning에서는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b57d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    loss = ...\n",
    "    return loss\n",
    "\n",
    "def training_step_end(self, losses):\n",
    "    gpu_0_loss = losses[0]\n",
    "    gpu_1_loss = losses[1]\n",
    "    return (gpu_0_loss + gpu_1_loss) * 1/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa9c3c6",
   "metadata": {},
   "source": [
    "> TIP: Valid loop와 Test loop는 동일한 구조입니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244c0fbb",
   "metadata": {},
   "source": [
    "### Logging\n",
    "\n",
    "Tensorboard나 여러분이 즐겨 사용하는 Logger 와/또는 Progress bar에 로깅하려면 LightningModule의 모든 메서드에서 호출할 수 있는 log() 메서드를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e126cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    self.log('my_metric', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e283a10",
   "metadata": {},
   "source": [
    "`log()` 메서드는 다음의 몇가지 옵션이 있습니다.\n",
    "\n",
    "- on_step (logs the metric at that step in training)\n",
    "- on_epoch (automatically accumulates and logs at the end of the epoch)\n",
    "- prog_bar (logs to the progress bar)\n",
    "- logger (logs to the logger like Tensorboard)\n",
    "\n",
    "로그가 호출된 위치에 따라 Lightning은 올바른 모드를 자동으로 결정합니다. 그러나 물론 플래그를 수동으로 설정하여 기본 동작을 무시할 수 있습니다.\n",
    "\n",
    "> NOTE: on_epoch=True로 설정하면 전체 훈련 에포크 동안 기록된 값이 누적됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f224088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    self.log('my_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3c6fad",
   "metadata": {},
   "source": [
    "> Note: Porgress bar에 표시된 손실 값은 마지막 값에 대해 평균되므로 학습/검증 단계에서 반환된 실제 손실과 다릅니다.\n",
    "\n",
    "로거의 모든 방법을 직접 사용할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d70dc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(self, batch, batch_idx):\n",
    "    tensorboard = self.logger.experiment\n",
    "    tensorboard.any_summary_writer_method_you_want())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2619d2",
   "metadata": {},
   "source": [
    "훈련이 시작되면 즐겨 사용하는 로거를 사용하거나 Tensorboard 로그를 부팅하여 로그를 볼 수 있습니다.\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir ./lightning_logs\n",
    "```\n",
    "\n",
    "> NOTE: Lightning은 Progress bar에 training_step에서 반환된 손실 값을 자동으로 표시합니다. 따라서 self.log('loss', loss, prog_bar=True)와 같이 명시적으로 기록할 필요가 없습니다.\n",
    "\n",
    "자세한 사항은 [loggers](https://pytorch-lightning.readthedocs.io/en/latest/common/loggers.html) docs를 참고하세요.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3672d0",
   "metadata": {},
   "source": [
    "### Optional extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae6b0a",
   "metadata": {},
   "source": [
    "#### Callbacks\n",
    "\n",
    "콜백은 훈련 루프의 임의의 부분에서 실행할 수 있는 임의의 Self-contained program입니다.\n",
    "\n",
    "다음은 그다지 화려하지 않은 Learning rate decay rule을 추가하는 예입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdc1dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "class DecayLearningRate(Callback):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.old_lrs = []\n",
    "\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        # track the initial learning rates\n",
    "        for opt_idx, optimizer in enumerate(trainer.optimizers):\n",
    "            group = [param_group['lr'] for param_group in optimizer.param_groups]\n",
    "            self.old_lrs.append(group)\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module, outputs):\n",
    "        for opt_idx, optimizer in enumerate(trainer.optimizers):\n",
    "            old_lr_group = self.old_lrs[opt_idx]\n",
    "            new_lr_group = []\n",
    "            for p_idx, param_group in enumerate(optimizer.param_groups):\n",
    "                old_lr = old_lr_group[p_idx]\n",
    "                new_lr = old_lr * 0.98\n",
    "                new_lr_group.append(new_lr)\n",
    "                param_group['lr'] = new_lr\n",
    "            self.old_lrs[opt_idx] = new_lr_group\n",
    "\n",
    "# And pass the callback to the Trainer\n",
    "decay_callback = DecayLearningRate()\n",
    "trainer = Trainer(callbacks=[decay_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54f92fc",
   "metadata": {},
   "source": [
    "Callback으로 할 수 있는 것들:\n",
    "\n",
    "- 훈련의 특정 지점에서 이메일 발송\n",
    "- Grow the model\n",
    "- Update learning rates\n",
    "- Visualize gradients\n",
    "- …\n",
    "- 상상할 수 있는 모든것들\n",
    "\n",
    "자세한 것은 [Callback](https://pytorch-lightning.readthedocs.io/en/latest/extensions/callbacks.html) docs를 참고하세요.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8682da",
   "metadata": {},
   "source": [
    "### LightningDataModules\n",
    "\n",
    "DataLoader와 데이터 처리 코드는 결국 흩어지는 경향이 있습니다. LightningDataModule로 구성하여 데이터 코드를 재사용 가능하게 구현하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f09006",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(LightningDataModule):\n",
    "\n",
    "      def __init__(self, batch_size=32):\n",
    "          super().__init__()\n",
    "          self.batch_size = batch_size\n",
    "\n",
    "      # When doing distributed training, Datamodules have two optional arguments for\n",
    "      # granular control over download/prepare/splitting data:\n",
    "\n",
    "      # OPTIONAL, called only on 1 GPU/machine\n",
    "      def prepare_data(self):\n",
    "          MNIST(os.getcwd(), train=True, download=True)\n",
    "          MNIST(os.getcwd(), train=False, download=True)\n",
    "\n",
    "      # OPTIONAL, called for every GPU/machine (assigning state is OK)\n",
    "      def setup(self, stage: Optional[str] = None):\n",
    "          # transforms\n",
    "          transform=transforms.Compose([\n",
    "              transforms.ToTensor(),\n",
    "              transforms.Normalize((0.1307,), (0.3081,))\n",
    "          ])\n",
    "          # split dataset\n",
    "          if stage in (None, 'fit'):\n",
    "              mnist_train = MNIST(os.getcwd(), train=True, transform=transform)\n",
    "              self.mnist_train, self.mnist_val = random_split(mnist_train, [55000, 5000])\n",
    "          if stage == (None, 'test'):\n",
    "              self.mnist_test = MNIST(os.getcwd(), train=False, transform=transform)\n",
    "\n",
    "      # return the dataloader for each split\n",
    "      def train_dataloader(self):\n",
    "          mnist_train = DataLoader(self.mnist_train, batch_size=self.batch_size)\n",
    "          return mnist_train\n",
    "\n",
    "      def val_dataloader(self):\n",
    "          mnist_val = DataLoader(self.mnist_val, batch_size=self.batch_size)\n",
    "          return mnist_val\n",
    "\n",
    "      def test_dataloader(self):\n",
    "          mnist_test = DataLoader(self.mnist_test, batch_size=self.batch_size)\n",
    "          return mnist_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0e7230",
   "metadata": {},
   "source": [
    "LightningDataModule은 다양한 프로젝트에서 Data split 및 Transforms를 공유하고 재사용할 수 있도록 설계되었습니다. 다운로드, Tokenizing, Processing 등 데이터를 처리하는 데 필요한 모든 단계를 캡슐화합니다.\n",
    "\n",
    "이제 LightningDataModule을 `Trainer`에 간단히 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74315deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "model = LitModel()\n",
    "\n",
    "# init data\n",
    "dm = MNISTDataModule()\n",
    "\n",
    "# train\n",
    "trainer = pl.Trainer()\n",
    "trainer.fit(model, dm)\n",
    "\n",
    "# test\n",
    "trainer.test(datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c04f6ff",
   "metadata": {},
   "source": [
    "DataModules는 특히 데이터를 기반으로 모델을 구축하는 데 유용합니다. 자세한 것은 [datamodules](https://pytorch-lightning.readthedocs.io/en/latest/extensions/datamodules.html) docs를 읽어보세요.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0669915c",
   "metadata": {},
   "source": [
    "### Debugging\n",
    "\n",
    "Lightning에는 디버깅을 위한 많은 도구가 있습니다. 다음은 그 중 일부의 예입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94ce40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only 10 train batches and 3 val batches\n",
    "trainer = Trainer(limit_train_batches=10, limit_val_batches=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79868509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically overfit the sane batch of your model for a sanity test\n",
    "trainer = Trainer(overfit_batches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c6e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit test all the code- hits every line of your code once to see if you have bugs,\n",
    "# instead of waiting hours to crash on validation\n",
    "trainer = Trainer(fast_dev_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec28fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train only 20% of an epoch\n",
    "trainer = Trainer(limit_train_batches=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0063295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run validation every 25% of a training epoch\n",
    "trainer = Trainer(val_check_interval=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa6dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile your code to find speed/memory bottlenecks\n",
    "Trainer(profiler=\"simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad446bda",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31359f9",
   "metadata": {},
   "source": [
    "## 나머지 멋진 특징들\n",
    "\n",
    "첫 번째 Lightning 모델을 정의하고 교육한 후에는 다음과 같은 다른 멋진 기능을 사용해 볼 수 있습니다.\n",
    "\n",
    "- [Automatic early stopping](https://pytorch-lightning.readthedocs.io/en/latest/common/early_stopping.html)\n",
    "- [Automatic truncated-back-propagation-through-time](https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html#truncated-bptt-steps)\n",
    "- [Automatically scale your batch size](https://pytorch-lightning.readthedocs.io/en/latest/advanced/training_tricks.html#auto-scaling-of-batch-size)\n",
    "- [Automatically find a good learning rate](https://pytorch-lightning.readthedocs.io/en/latest/advanced/lr_finder.html)\n",
    "- [Load checkpoints directly from S3](https://pytorch-lightning.readthedocs.io/en/latest/common/weights_loading.html#checkpoint-loading)\n",
    "- [Scale to massive compute clusters](https://pytorch-lightning.readthedocs.io/en/latest/clouds/cluster.html)\n",
    "- [Use multiple dataloaders per train/val/test loop](https://pytorch-lightning.readthedocs.io/en/latest/advanced/multiple_loaders.html)\n",
    "- [Use multiple optimizers to do reinforcement learning or even GANs](https://pytorch-lightning.readthedocs.io/en/latest/common/optimizers.html#use-multiple-optimizers-like-gans)\n",
    "\n",
    "혹은 우리의 [가이드](https://pytorch-lightning.readthedocs.io/en/latest/starter/introduction_guide.html)를 읽고 더 배워보세요!\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db10acf",
   "metadata": {},
   "source": [
    "### Grid AI\n",
    "\n",
    "Grid AI는 클라우드에서 Large scale training 및 Tunning을 위한 기본 솔루션입니다.\n",
    "\n",
    "[여기에서 GitHub 또는 Google 계정으로 무료로 시작해보세요!](https://www.grid.ai/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90921705",
   "metadata": {},
   "source": [
    "### Community\n",
    "\n",
    "우리 커뮤니티는 핵심 유지 관리자와 수천 명의 전문 연구원으로 구성되어 [Slack](https://pytorch-lightning.slack.com/join/shared_invite/zt-pw5v393p-qRaDgEk24~EjiZNBpSQFgQ#/shared-invite/email) 및 [GitHub Discussions](https://github.com/PyTorchLightning/pytorch-lightning/discussions)에서 활발히 활동하고 있습니다. 놀러 가거나 Lightning 질문을 하거나 연구에 대해 토론할 수도 있습니다!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc962d7e",
   "metadata": {},
   "source": [
    "### Masterclass\n",
    "\n",
    "또한 Lightning의 고급 사용법을 가르치는 마스터 클래스도 제공합니다.\n",
    "[![pl](https://pytorch-lightning.readthedocs.io/en/latest/_images/PTL101_youtube_thumbnail.jpg)](https://www.youtube.com/playlist?list=PLaMu-SDt_RB5NUm67hU2pdE75j6KaIOv2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
